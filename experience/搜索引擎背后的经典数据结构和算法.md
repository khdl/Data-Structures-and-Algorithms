# 搜索引擎背后的经典数据结构和算法

搜索引擎大致可以分为四部分：搜集、分析、索引、查询

### 搜集

搜集就是利用爬虫爬取网页

搜索引擎把整个互联网看做数据结构中的有向图，把每个网页看作一个顶点。如果每个网页中包含另一个网页的链接，两个顶点之间就有一条有向边。利用图的遍历搜索算法。

图的遍历算法有两种，BFS和DFS，搜索引擎采用的BFS，先找一些知名的网站的链接，作为种子网页链接放在队列中。

待爬取网页的链接文件、网页重判文件、原始网页存储文件网页链接及其编号对应的文件

### 分析

分析主要步骤： 抽取网页文本信息、分词并创建临时索引

抽取网页文本信息就是把js代码、HTML标签去掉

分词有许多思路，比较复杂，一种简单的思路是基于字典和规则的分词方法。

经过分析阶段，得到两个重要的文件，分别是临时索引文件和单词编号文件。

### 索引

主要是将分析阶段产生的临时索引，构建成倒序索引。

考虑到临时索引文件一般都很大，搜索引擎一般采用多路归并排序的 方法来实现。

进过索引阶段，得到两个有价值的文件，倒排索引文件和记录单词编号在索引文件中偏移位置的文件。


### 查询

前三个阶段的处理是为最后的查询做铺垫。

除了倒排索引文件其余的都比较小。小文件加载在内存中。

用户输入后，对输入进行分词处理，查询对应的分词。

### 过程涉及的数据结构和算法

图、散列表、Trie树、布隆过滤器、单模式字符串匹配、AC自动机、BFS、归并排序



